{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Letâ€™s make a DQN: Debugging\n",
    "\n",
    "https://gym.openai.com/envs/MountainCar-v0/\n",
    "\n",
    "Some useful resources:\n",
    "  * https://jaromiru.com/2016/10/12/lets-make-a-dqn-debugging/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gym\n",
    "from tensorflow.keras import models, layers, optimizers\n",
    "from replay_buffer import ReplayBuffer\n",
    "from IPython.display import clear_output\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation shape: (2,)\n",
      "Number of actions: 2\n",
      "Example state: [-0.48477658  0.        ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1488c7588>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#spawn game instance for tests\n",
    "env = gym.make(\"MountainCar-v0\").env #create raw env\n",
    "\n",
    "observation_shape = env.observation_space.shape\n",
    "n_actions = 2 # We simplify to left and right action\n",
    "\n",
    "print(\"Observation shape: {}\".format(observation_shape))\n",
    "print(\"Number of actions: {}\".format(n_actions))\n",
    "\n",
    "print(\"Example state: {}\".format(env.reset()))\n",
    "plt.imshow(env.render('rgb_array'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How many random steps are needed to solve it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean number of steps: 7953.1\n"
     ]
    }
   ],
   "source": [
    "def solve_randomly():\n",
    "    env.reset()\n",
    "    for step in range(100_000):\n",
    "        a = np.random.choice([0, 2])\n",
    "        s_next, r, done, info = env.step(a)\n",
    "        if done:\n",
    "            break\n",
    "    return step\n",
    "            \n",
    "## Look for 10 solution using random policy\n",
    "solution_steps = []\n",
    "for _ in range(10):\n",
    "    steps = solve_randomly()\n",
    "    solution_steps.append(steps)\n",
    "    \n",
    "print('Mean number of steps: {} (std={})'.format(np.mean(solution_steps), np.std(solution_steps)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare\n",
    "\n",
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.0003\n",
    "REPLAY_BUFFER_SIZE = 100_000\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "GAMMA = 0.99\n",
    "\n",
    "MAX_EPSILON = 1\n",
    "MIN_EPSILON = 0.1\n",
    "LAMBDA = 0.001      # speed of the decay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode action\n",
    "def encode_action(a):\n",
    "    return a if a == 0 else 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Agent\n",
    "\n",
    "We will use RandomAgent as a starting point since it gives higher probability of solving the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomAgent:\n",
    "    replay_buffer = ReplayBuffer(size=REPLAY_BUFFER_SIZE)\n",
    "\n",
    "    def __init__(self, action_count):\n",
    "        self.action_count = action_count\n",
    "\n",
    "    def act(self, s):\n",
    "        return random.randint(0, self.action_count-1)\n",
    "\n",
    "    def observe(self, sample):  # in (s, a, r, s_, d) format\n",
    "        self.replay_buffer.add(sample)\n",
    "\n",
    "    def replay(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Policy Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.03105736, -0.14799583], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class QNetwork:\n",
    "    \n",
    "    def __init__(self, input_shape, n_actions, alpha=LEARNING_RATE):\n",
    "        self.input_shape = input_shape\n",
    "        self.output_shape = n_actions\n",
    "        self.alpha = alpha\n",
    "        self.model = self._build_network()\n",
    "\n",
    "    def _build_network(self):\n",
    "        model = models.Sequential()\n",
    "        model.add(layers.InputLayer(self.input_shape))\n",
    "        model.add(layers.Dense(64, activation='relu'))\n",
    "        model.add(layers.Dense(self.output_shape, activation='linear'))\n",
    "        opt = optimizers.RMSprop(lr=self.alpha)\n",
    "        model.compile(loss='mse', optimizer=opt)\n",
    "        return model\n",
    "    \n",
    "    def predict(self, state):\n",
    "        \"\"\"Make prediction for single state and return q values for all actions\"\"\"\n",
    "        s = np.expand_dims(state, axis=0)\n",
    "        return self.model.predict(s)[0]\n",
    "    \n",
    "    def predict_batch(self, states):\n",
    "        \"\"\"Make prediction for list of states\"\"\"\n",
    "        return self.model.predict(states)\n",
    "    \n",
    "    def train(self, x, y):\n",
    "        self.model.fit(x, y, batch_size=64, verbose=0)\n",
    "\n",
    "        \n",
    "network = QNetwork(observation_shape, n_actions)\n",
    "network.predict(env.reset())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper for building training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ok!\n"
     ]
    }
   ],
   "source": [
    "def build_training_set(qvalues, qvalues_next, actions, rewards, dones, gamma=0.99):\n",
    "    \"\"\"\n",
    "    Create training set for QNetwork.\n",
    "    Params:\n",
    "      qvalues           - Q values for the starting state\n",
    "      qvalues_next      - Q values for the state the next state\n",
    "      actions           - Actions taken\n",
    "      rewards           - Rewards received after taking action \n",
    "      dones             - Did this action end the episode?\n",
    "      \n",
    "    Returns:\n",
    "      Expected qvalues\n",
    "    \"\"\"\n",
    "    y = qvalues.copy()\n",
    "    next_rewards = np.where(dones, np.zeros(rewards.shape), np.max(qvalues_next, axis=1))\n",
    "    y[np.arange(y.shape[0]), actions] = rewards + gamma * next_rewards\n",
    "    return y\n",
    "\n",
    "\n",
    "# Some tests\n",
    "qvalues = np.zeros((5, n_actions))\n",
    "qvalues2 = np.ones((5, n_actions))\n",
    "actions = np.array([0, 1, 0, 1, 0])\n",
    "rewards = np.array([1, 2, 3, 4, 5])\n",
    "dones = np.array([False, False, False, False, True])\n",
    "expected_y = np.array([[2, 0], [0, 3], [4, 0], [0, 5], [5, 0]])\n",
    "y = build_training_set(qvalues, qvalues2, actions, rewards, dones, 1.0)\n",
    "assert np.array_equal(y, expected_y), 'Wrong expected qvalue calculated'\n",
    "print('Ok!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
