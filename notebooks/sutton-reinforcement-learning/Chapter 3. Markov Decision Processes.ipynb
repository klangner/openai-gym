{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Markov Decision Processes \n",
    "\n",
    "MDP formally describes environment for reinforcement learning. Where the environment is fully observable.\n",
    "\n",
    "MDP are important since almost all RL problems can be described as MDP (event partially observed).\n",
    "\n",
    "\n",
    "## Definitions\n",
    "\n",
    "### Markov property\n",
    "\n",
    "MDP is a process which contains Markov property. It means that the current state only depends on the previous state, \n",
    "not the whole history:\n",
    "\n",
    "$$ \\Pr( S_{t+1} \\mid S_{t} ) =  \\Pr( S_{t+1} \\mid S_1, ..., S_{t} ) $$\n",
    "\n",
    "\n",
    "### Markov Process (Markov chain)\n",
    "\n",
    "MP is a tuple $<S,P>$ where\n",
    " * S - List of all states\n",
    " * P - Transition probability table between states\n",
    " \n",
    "\n",
    "### Belman equation\n",
    "\n",
    "\n",
    "$$ v(s) = \\mathbb{E}[R_{t+1} + \\gamma v(S_{t+1}) | S_t = s] $$\n",
    "\n",
    "Using matrices\n",
    "\n",
    "$$ v = R + \\gamma P v $$\n",
    " \n",
    " \n",
    "### Markov Decision Process \n",
    "\n",
    "MDP is a tuple $<S, A, P, R, \\gamma>$\n",
    "\n",
    "where:\n",
    "\n",
    " * S - finite set of states\n",
    " * A - finite set of actions\n",
    " * P - Transistion probability matrix\n",
    " * R - Reward function\n",
    " * $\\gamma$ - discount factor $\\gamma \\in [0,1]$\n",
    " \n",
    " \n",
    "### Policy\n",
    "\n",
    "Policy defines behaviour of the agent.\n",
    "\n",
    "$$ \\pi(a|s) = \\Pr[A_t = a | S_t = s] $$\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
